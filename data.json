[
  {
    "Chapter": 1,
    "หัวข้อ": "คอมพิวเตอร์แบบเดิมทำตามคำสั่งของมนุษย์ แต่ AI สามารถเรียนรู้และสร้างสิ่งใหม่ได้ด้วยตัวเอง",
    "คำถาม": "ข้อใดอธิบายความแตกต่างระหว่างคอมพิวเตอร์แบบเดิมกับ AI ได้ถูกต้องที่สุด",
    "ตัวเลือก A": "คอมพิวเตอร์แบบเดิมทำตามคำสั่งเท่านั้น ส่วน AI สามารถเรียนรู้และสร้างสิ่งใหม่ได้",
    "ตัวเลือก B": "คอมพิวเตอร์แบบเดิมใช้ข้อมูลมากกว่า AI",
    "ตัวเลือก C": "AI ทำงานช้ากว่าคอมพิวเตอร์ทั่วไป",
    "ตัวเลือก D": "ทั้งสองแบบเหมือนกัน",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "สะท้อนความเข้าใจพื้นฐานของแนวคิด “AI เรียนรู้และสร้างสรรค์ได้” ซึ่งต่างจากระบบที่ทำตามคำสั่งแบบเดิม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 1,
    "หัวข้อ": "Generative AI คือ AI ที่สามารถสร้างสิ่งใหม่ เช่น บทความ ภาพ หรือเพลง จากสิ่งที่เรียนรู้",
    "คำถาม": "Generative AI แตกต่างจาก AI แบบดั้งเดิมอย่างไร",
    "ตัวเลือก A": "ใช้ข้อมูลน้อยกว่า",
    "ตัวเลือก B": "เน้นสร้างผลลัพธ์ใหม่จากความรู้ที่เรียนรู้",
    "ตัวเลือก C": "ไม่สามารถตอบสนองแบบเรียลไทม์",
    "ตัวเลือก D": "ใช้ได้เฉพาะกับภาพเท่านั้น",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Reinforce ความเข้าใจว่า Generative AI มีความสามารถ “สร้างเนื้อหาใหม่” ไม่ใช่แค่ประมวลผลข้อมูลเดิม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 1,
    "หัวข้อ": "Machine Learning คือการให้อัลกอริทึมเรียนรู้จากข้อมูลโดยไม่ต้องสั่งทุกขั้นตอน",
    "คำถาม": "“Machine Learning” ทำงานแตกต่างจากการเขียนโปรแกรมแบบเดิมอย่างไร",
    "ตัวเลือก A": "ไม่ต้องใช้ข้อมูลฝึก",
    "ตัวเลือก B": "มีการเรียนรู้จากข้อมูลโดยไม่ต้องระบุทุกขั้นตอน",
    "ตัวเลือก C": "ใช้แค่กฎตายตัวเท่านั้น",
    "ตัวเลือก D": "ต้องเขียนโค้ดทุกบรรทัดเอง",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ทดสอบความเข้าใจแนวคิด “การเรียนรู้ของเครื่อง” ที่เป็นรากฐานของ AI ยุคใหม่",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 1,
    "หัวข้อ": "Deep Learning ใช้โครงข่ายประสาทเทียม (Neural Networks) หลายชั้นเพื่อเข้าใจข้อมูลเชิงลึก",
    "คำถาม": "“Deep Learning” แตกต่างจาก “Machine Learning” แบบทั่วไปอย่างไร",
    "ตัวเลือก A": "ใช้ข้อมูลน้อยกว่า",
    "ตัวเลือก B": "ใช้โครงข่ายประสาทเทียมหลายชั้นเพื่อเข้าใจรูปแบบเชิงลึกของข้อมูล",
    "ตัวเลือก C": "ใช้เฉพาะกับข้อมูลตัวเลข",
    "ตัวเลือก D": "ไม่ต้องการฮาร์ดแวร์ที่มีพลังสูง",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "วัดความเข้าใจเทคนิค Deep Learning ที่เพิ่มความซับซ้อนและศักยภาพของ AI",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 1,
    "หัวข้อ": "LLM คือโมเดลภาษาขนาดใหญ่ที่ทำนายคำถัดไปจากบริบทก่อนหน้า",
    "คำถาม": "หลักการทำงานหลักของโมเดลภาษา (LLM) คืออะไร",
    "ตัวเลือก A": "การจดจำทุกประโยคในฐานข้อมูล",
    "ตัวเลือก B": "การทำนายคำถัดไปตามบริบทของคำก่อนหน้า",
    "ตัวเลือก C": "การแปลทุกภาษาพร้อมกัน",
    "ตัวเลือก D": "การค้นหาข้อมูลจากอินเทอร์เน็ตแบบเรียลไทม์",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Reinforce ความเข้าใจของผู้เรียนต่อกลไก “Next Word Prediction” ซึ่งเป็นหัวใจของ LLM",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 1,
    "หัวข้อ": "LLM ผ่านการฝึกด้วย Self-supervised, Supervised Fine-tuning และ RLHF",
    "คำถาม": "จุดประสงค์ของขั้นตอน RLHF คืออะไร",
    "ตัวเลือก A": "ให้โมเดลท่องจำข้อมูลเพิ่มขึ้น",
    "ตัวเลือก B": "ปรับโมเดลให้ตอบตรงกับความต้องการของผู้ใช้มากขึ้น",
    "ตัวเลือก C": "ลดขนาดโมเดลให้เล็กลง",
    "ตัวเลือก D": "ทำให้โมเดลตอบเร็วขึ้น",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "RLHF คือการให้มนุษย์ช่วยประเมินคำตอบเพื่อให้โมเดลเรียนรู้พฤติกรรมที่มนุษย์ต้องการ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 1,
    "หัวข้อ": "Generative AI สามารถสร้างภาพ เสียง วิดีโอ และโค้ดจากคำบรรยายได้",
    "คำถาม": "ข้อใดต่อไปนี้เป็นตัวอย่างของ Generative AI ที่ถูกต้อง",
    "ตัวเลือก A": "โปรแกรมแปลภาษา",
    "ตัวเลือก B": "โปรแกรมสร้างภาพจากข้อความ",
    "ตัวเลือก C": "ระบบค้นหาข้อมูล",
    "ตัวเลือก D": "ระบบล็อกอินอัตโนมัติ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ทดสอบการเชื่อมโยงแนวคิดกับการใช้งานจริงของ Generative AI",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 1,
    "หัวข้อ": "โมเดลภาษาไทย เช่น OpenThaiGPT, Typhoon, Pratumma LLM พัฒนาโดยคนไทย",
    "คำถาม": "การพัฒนาโมเดลภาษาไทยมีความสำคัญอย่างไร",
    "ตัวเลือก A": "เพื่อแข่งขันกับบริษัทต่างชาติเท่านั้น",
    "ตัวเลือก B": "เพื่อให้โมเดลเข้าใจภาษาและวัฒนธรรมไทยอย่างลึกซึ้ง",
    "ตัวเลือก C": "เพื่อทำให้การตอบเร็วขึ้น",
    "ตัวเลือก D": "เพื่อใช้เฉพาะงานราชการ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ส่งเสริมการตระหนักรู้ถึงคุณค่าของการพัฒนา AI ให้สอดคล้องกับบริบททางภาษาและวัฒนธรรมของไทย",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 2,
    "หัวข้อ": "งานวิจัยของ OpenAI อธิบายว่าทำไมโมเดลไม่พูดว่า “I don’t know”",
    "คำถาม": "เหตุใด AI จึงเลือก “เดา” แทนที่จะตอบว่า “ไม่รู้”",
    "ตัวเลือก A": "เพราะระบบการประเมินให้คะแนนเฉพาะคำตอบที่ถูกต้อง",
    "ตัวเลือก B": "เพราะโมเดลไม่เข้าใจภาษา",
    "ตัวเลือก C": "เพราะโมเดลต้องการหลอกมนุษย์",
    "ตัวเลือก D": "เพราะไม่มีข้อมูลพอในระบบ",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "AI ถูกฝึกให้เดาเพราะระบบให้รางวัลเฉพาะคำตอบที่ถูก ทำให้เลือกตอบมากกว่าปฏิเสธ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 2,
    "หัวข้อ": "กรณีรถ Tesla พุ่งชนรถพ่วงโดยไม่ลดความเร็ว",
    "คำถาม": "กรณีนี้สะท้อนความเสี่ยงด้านใดของ AI",
    "ตัวเลือก A": "การหลอน (Hallucination)",
    "ตัวเลือก B": "ความล้มเหลวในการรับรู้และตัดสินใจ",
    "ตัวเลือก C": "การคำนวณเร็วเกินไป",
    "ตัวเลือก D": "การขาดข้อมูลภาพ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "สะท้อนความเสี่ยงของ AI ด้านการตัดสินใจอัตโนมัติที่ผิดพลาดแม้เห็นวัตถุชัดเจน",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 2,
    "หัวข้อ": "ตัวอย่างนาฬิกา 10:10 แสดงอคติของข้อมูล (Bias)",
    "คำถาม": "ข้อใดเป็นตัวอย่างของ “Bias” ในข้อมูลที่ใช้ฝึก AI",
    "ตัวเลือก A": "AI ทำนายเวลาผิดเพราะเห็นแต่นาฬิกาตั้งไว้ที่ 10:10",
    "ตัวเลือก B": "AI ไม่สามารถสร้างภาพใหม่ได้",
    "ตัวเลือก C": "AI แปลภาษาผิด",
    "ตัวเลือก D": "AI ตอบช้าเกินไป",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "ตัวอย่าง Bias จากข้อมูลที่ไม่หลากหลาย ทำให้ AI เรียนรู้ผิดพลาดจากรูปแบบที่ซ้ำเดิม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 2,
    "หัวข้อ": "การที่ AI เดาผลลัพธ์โดยขาดบริบทเพียงพอ",
    "คำถาม": "เหตุผลสำคัญที่ AI ตอบผิดหรือหลอนได้คืออะไร",
    "ตัวเลือก A": "เพราะโมเดลไม่มีข้อมูลตัวอย่างเพียงพอหรือบริบทไม่ครบ",
    "ตัวเลือก B": "เพราะโมเดลจงใจตอบผิด",
    "ตัวเลือก C": "เพราะโมเดลไม่สามารถคำนวณได้",
    "ตัวเลือก D": "เพราะผู้ใช้ถามเร็วเกินไป",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "การขาดข้อมูลอ้างอิงหรือบริบททำให้ AI ต้องเดานอกช่วง → เกิด Extrapolation ผิดพลาด",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 2,
    "หัวข้อ": "การที่ AI สร้างภาพผิดจากของจริงแต่ยังดูสมจริง",
    "คำถาม": "ปรากฏการณ์นี้เรียกว่าอะไร",
    "ตัวเลือก A": "Overfitting",
    "ตัวเลือก B": "Hallucination",
    "ตัวเลือก C": "Reinforcement",
    "ตัวเลือก D": "Translation Error",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI สร้างสิ่งที่ดูสมจริงแต่ไม่ถูกต้อง เรียกว่า “การหลอน” หรือ Hallucination",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 2,
    "หัวข้อ": "การเปรียบเทียบ Rule-based กับ Learned Model",
    "คำถาม": "ความแตกต่างหลักระหว่าง Rule-based Model และ Learned Model คืออะไร",
    "ตัวเลือก A": "Rule-based ใช้การเรียนรู้จากข้อมูล ส่วน Learned ใช้สูตรคงที่",
    "ตัวเลือก B": "Rule-based ใช้กฎคณิตศาสตร์แน่นอน ส่วน Learned Model เรียนรู้จากตัวอย่างข้อมูล",
    "ตัวเลือก C": "ทั้งคู่ทำงานเหมือนกัน",
    "ตัวเลือก D": "Learned Model ไม่สามารถคาดการณ์ได้",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "วัดความเข้าใจแนวคิดพื้นฐานของ “สมการ vs การเรียนรู้จากข้อมูล”",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 2,
    "หัวข้อ": "ตัวอย่างจากซีรีส์ 3-body problem และพยากรณ์อากาศ",
    "คำถาม": "ปัญหาที่เหมาะกับการใช้ AI คือแบบใด",
    "ตัวเลือก A": "ปัญหาที่มีกฎแน่นอนและคำนวณได้ชัดเจน",
    "ตัวเลือก B": "ปัญหาที่ซับซ้อนและไม่สามารถอธิบายด้วยสมการตายตัว",
    "ตัวเลือก C": "ปัญหาที่เกี่ยวข้องกับคณิตศาสตร์พื้นฐานเท่านั้น",
    "ตัวเลือก D": "ปัญหาที่ไม่ต้องใช้ข้อมูลจำนวนมาก",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI เหมาะกับปัญหาที่ซับซ้อน เช่น พยากรณ์อากาศ หรือระบบหลายปัจจัยที่ไม่สามารถใช้สมการแน่นอนได้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 2,
    "หัวข้อ": "การคาดเดาข้อมูลนอกช่วงข้อมูลเดิม (Extrapolation)",
    "คำถาม": "เหตุใด Extrapolation จึงมักให้ผลผิดพลาดมากกว่า Interpolation",
    "ตัวเลือก A": "เพราะต้องใช้สมการคณิตศาสตร์ซับซ้อนกว่า",
    "ตัวเลือก B": "เพราะคาดเดาค่านอกช่วงข้อมูลที่มี ทำให้ความไม่แน่นอนสูง",
    "ตัวเลือก C": "เพราะใช้ข้อมูลมากเกินไป",
    "ตัวเลือก D": "เพราะเป็นเทคนิคใหม่กว่า",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Extrapolation คือการทำนายนอกช่วงข้อมูลที่รู้ ทำให้โอกาสผิดสูงกว่าการคาดค่าในช่วง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 2,
    "หัวข้อ": "ตัวอย่างกราฟ PM2.5 อธิบายแนวคิดการคาดเดาข้อมูลที่หายไปในช่วง (Interpolation)",
    "คำถาม": "หลักการของ Interpolation คืออะไร",
    "ตัวเลือก A": "การคาดเดาข้อมูลที่อยู่นอกช่วงข้อมูลอ้างอิง",
    "ตัวเลือก B": "การคาดเดาข้อมูลภายในช่วงของข้อมูลอ้างอิง",
    "ตัวเลือก C": "การคำนวณค่าคงที่จากสูตร",
    "ตัวเลือก D": "การเดาคำตอบแบบสุ่ม",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Interpolation คือการประมาณค่าภายในช่วงของข้อมูลที่มีอยู่ เช่น การเดาค่าฝุ่นปี 2011 จากค่าปี 2010 และ 2012",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 2,
    "หัวข้อ": "ตัวอย่างการใช้ AI เติมคำในศิลาจารึกหรือภาพที่หายไป",
    "คำถาม": "การที่ AI เติมคำในศิลาจารึกหรือสร้างภาพส่วนที่ขาดหายไป เทียบได้กับหลักการใด",
    "ตัวเลือก A": "Extrapolation",
    "ตัวเลือก B": "Interpolation",
    "ตัวเลือก C": "Reinforcement",
    "ตัวเลือก D": "Bias Correction",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การเติมข้อมูลที่หายไปโดยอิงจากข้อมูลบริบทรอบ ๆ คือการทำ Interpolation",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 3,
    "หัวข้อ": "ทุกอัลกอริทึมมีอคติในระดับใดระดับหนึ่ง",
    "คำถาม": "วิธีที่ถูกต้องในการรับมือกับอคติใน AI คืออะไร",
    "ตัวเลือก A": "ปฏิเสธการใช้ AI ทันที",
    "ตัวเลือก B": "ตรวจสอบและตั้งคำถามกับข้อมูลและวิธีตัดสินของ AI",
    "ตัวเลือก C": "ใช้ AI โดยไม่ต้องตรวจสอบ",
    "ตัวเลือก D": "ให้ AI ตัดสินแทนมนุษย์ทั้งหมด",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "แนวทางที่ถูกต้องคือใช้ AI อย่างมีวิจารณญาณ ตรวจสอบแหล่งข้อมูลและผลลัพธ์เสมอ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 3,
    "หัวข้อ": "การเข้าใจอคติและขอบเขตของ AI",
    "คำถาม": "เพราะเหตุใดผู้ใช้ทั่วไปจึงควรรู้จักอคติใน AI",
    "ตัวเลือก A": "เพื่อจะได้หลีกเลี่ยงการใช้งาน AI",
    "ตัวเลือก B": "เพื่อใช้ AI อย่างชาญฉลาดและเป็นธรรมต่อทุกคน",
    "ตัวเลือก C": "เพื่อสร้าง AI ของตนเอง",
    "ตัวเลือก D": "เพื่อแข่งขันกับเทคโนโลยี",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การรู้เท่าทันอคติช่วยให้เราใช้ AI อย่างมีจริยธรรมและไม่ตัดสินผู้อื่นอย่างไม่ยุติธรรม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 3,
    "หัวข้อ": "ความโปร่งใสในระบบ AI",
    "คำถาม": "เหตุใดความโปร่งใส (Transparency) จึงสำคัญต่อการใช้ AI อย่างเป็นธรรม",
    "ตัวเลือก A": "ทำให้ผู้ใช้เชื่อถือได้และเข้าใจขอบเขตของระบบ",
    "ตัวเลือก B": "ทำให้ระบบทำงานเร็วขึ้น",
    "ตัวเลือก C": "ลดต้นทุนในการฝึกโมเดล",
    "ตัวเลือก D": "ทำให้ AI สร้างข้อมูลได้มากขึ้น",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "ความโปร่งใสช่วยให้ผู้ใช้รู้ว่า AI ถูกฝึกจากข้อมูลแบบใด และตัดสินใจอย่างไร",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 3,
    "หัวข้อ": "การใช้ AI ในการคัดเลือกพนักงานอาจสานต่ออคติจากการตัดสินใจในอดีต",
    "คำถาม": "ผลกระทบของอคติในระบบคัดเลือกผู้สมัครงานคืออะไร",
    "ตัวเลือก A": "ช่วยให้เลือกคนได้เร็วขึ้น",
    "ตัวเลือก B": "ทำให้บริษัทพลาดคนเก่งและไม่เป็นธรรม",
    "ตัวเลือก C": "เพิ่มโอกาสของผู้สมัครทุกคน",
    "ตัวเลือก D": "ลดความลำเอียงของมนุษย์ได้ทั้งหมด",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ระบบเรียนรู้อคติจากข้อมูลเดิม เช่น อายุ เพศ หรือพื้นเพ ทำให้ตัดสินใจไม่ยุติธรรม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 3,
    "หัวข้อ": "System Card หรือใบแจ้งส่วนผสมของ AI",
    "คำถาม": "จุดประสงค์ของ “System Card” คืออะไร",
    "ตัวเลือก A": "ช่วยให้ AI ตัดสินใจแทนมนุษย์ได้",
    "ตัวเลือก B": "เปิดเผยข้อมูลฝึก จุดแข็ง จุดอ่อนของโมเดล",
    "ตัวเลือก C": "แสดงราคาซื้อขายของโมเดล",
    "ตัวเลือก D": "ใช้เป็นใบอนุญาตให้ AI ทำงานได้",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "System Card คือเอกสารแสดงความโปร่งใสของ AI เพื่อให้ผู้ใช้เข้าใจข้อจำกัดของระบบ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 3,
    "หัวข้อ": "งานวิจัยของ MIT พบว่า AI จำแนกเพศคนผิวสีผิดพลาดสูง",
    "คำถาม": "งานวิจัยของ MIT ปี 2018 สะท้อนปัญหาอะไรในระบบ AI",
    "ตัวเลือก A": "การฝึกข้อมูลมากเกินไป",
    "ตัวเลือก B": "ความไม่หลากหลายของข้อมูลฝึก",
    "ตัวเลือก C": "การใช้โมเดลที่ซับซ้อนเกินไป",
    "ตัวเลือก D": "การเขียนโปรแกรมผิดพลาด",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "งานวิจัยพบว่า AI ล้มเหลวกับกลุ่มที่ไม่ถูกแทนในข้อมูลฝึก แสดงถึงปัญหา Representation Bias",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 3,
    "หัวข้อ": "ตัวอย่าง AI แสดงภาพ “nurse” เป็นผู้หญิงเกือบทั้งหมด",
    "คำถาม": "เหตุการณ์นี้เป็นตัวอย่างของอคติประเภทใด",
    "ตัวเลือก A": "Automation Bias",
    "ตัวเลือก B": "Representation Bias",
    "ตัวเลือก C": "Confirmation Bias",
    "ตัวเลือก D": "Gender Bias",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "เป็นตัวอย่างของ Representation Bias — ข้อมูลที่ใช้ฝึกไม่สะท้อนความหลากหลายของความเป็นจริง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 3,
    "หัวข้อ": "ระบบ PredPol ใช้ข้อมูลการจับกุมในอดีตและตอกย้ำอคติเดิม",
    "คำถาม": "ปรากฏการณ์ที่ระบบ PredPol ตอกย้ำอคติเดิมเรียกว่าอะไร",
    "ตัวเลือก A": "Confirmation Bias",
    "ตัวเลือก B": "Reinforcement Bias",
    "ตัวเลือก C": "Feedback Loop Bias",
    "ตัวเลือก D": "Predictive Bias",
    "คำตอบที่ถูก": "C",
    "คำอธิบาย": "Feedback Loop Bias คือการนำข้อมูลที่มีอคติกลับมาใช้ซ้ำ ทำให้อคติเพิ่มขึ้นเรื่อย ๆ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 3,
    "หัวข้อ": "อคติคือกลไกทางความคิดของมนุษย์ที่ช่วยให้ตัดสินใจเร็วขึ้น แต่บางครั้งก็นำมาซึ่งความไม่ยุติธรรม",
    "คำถาม": "ทำไมอคติของมนุษย์จึงเป็นปัญหาเมื่อถูกฝังใน AI",
    "ตัวเลือก A": "เพราะทำให้ AI ตัดสินใจช้าลง",
    "ตัวเลือก B": "เพราะ AI จะขาดความคิดสร้างสรรค์",
    "ตัวเลือก C": "เพราะอคติเล็ก ๆ อาจกลายเป็นอคติขนาดใหญ่ในระบบ",
    "ตัวเลือก D": "เพราะอคติทำให้ข้อมูลสูญหาย",
    "คำตอบที่ถูก": "C",
    "คำอธิบาย": "การที่ AI เรียนรู้อคติของมนุษย์ทำให้ระบบตัดสินใจไม่เป็นธรรมและกระทบต่อคนจำนวนมาก",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 3,
    "หัวข้อ": "AI ถูกสอนจากข้อมูลของมนุษย์ ซึ่งอาจมีอคติแฝงอยู่",
    "คำถาม": "สาเหตุหลักที่ทำให้ AI มีอคติ (Algorithmic Bias) คืออะไร",
    "ตัวเลือก A": "การคำนวณผิดพลาดของระบบ",
    "ตัวเลือก B": "การฝึกจากข้อมูลของมนุษย์ที่มีอคติอยู่แล้ว",
    "ตัวเลือก C": "การใช้ภาษาที่ซับซ้อนเกินไป",
    "ตัวเลือก D": "การเขียนโค้ดไม่สมบูรณ์",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI เรียนรู้จากข้อมูลของมนุษย์ ซึ่งอาจสะท้อนมุมมองและอคติทางสังคมโดยไม่รู้ตัว",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 4,
    "หัวข้อ": "การใช้ AI ที่เน้นให้แหล่งอ้างอิง",
    "คำถาม": "AI ใดต่อไปนี้ขึ้นชื่อเรื่องการให้แหล่งอ้างอิงที่ตรวจสอบได้",
    "ตัวเลือก A": "DALL·E",
    "ตัวเลือก B": "Perplexity",
    "ตัวเลือก C": "Copilot",
    "ตัวเลือก D": "Whisper",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Perplexity AI ออกแบบให้ตอบคำถามพร้อมแหล่งอ้างอิงที่ตรวจสอบได้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 4,
    "หัวข้อ": "การตรวจสอบข้อมูลเชิงวิชาการ",
    "คำถาม": "หากต้องการตรวจสอบว่างานวิจัยมีจริงหรือไม่ ควรใช้เครื่องมือใด",
    "ตัวเลือก A": "Wikipedia",
    "ตัวเลือก B": "Google Scholar",
    "ตัวเลือก C": "Instagram",
    "ตัวเลือก D": "YouTube",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Google Scholar เป็นแหล่งค้นงานวิจัยเชิงวิชาการที่เชื่อถือได้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 4,
    "หัวข้อ": "เครื่องมือช่วยตรวจสอบข้อมูล",
    "คำถาม": "เครื่องมือใดต่อไปนี้เหมาะกับการตรวจสอบข่าวจริงหรือข่าวปลอม",
    "ตัวเลือก A": "CoFact",
    "ตัวเลือก B": "Google Maps",
    "ตัวเลือก C": "Canva",
    "ตัวเลือก D": "Chatbot",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "CoFact เป็นเว็บ Fact-checker ที่ช่วยตรวจสอบข่าวปลอมในภาษาไทย",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 4,
    "หัวข้อ": "ตัวอย่างภาษาชี้นำอารมณ์ เช่น “แน่นอนที่สุด!”, “สุดยอดเทคโนโลยี”",
    "คำถาม": "คำตอบที่ใช้ภาษาชี้นำอารมณ์มีความเสี่ยงอย่างไร",
    "ตัวเลือก A": "ทำให้ผู้ใช้อยากอ่านต่อ",
    "ตัวเลือก B": "กระตุ้นอารมณ์แทนที่จะให้ข้อมูลจริง",
    "ตัวเลือก C": "ทำให้ข้อมูลแม่นยำขึ้น",
    "ตัวเลือก D": "ไม่มีผลต่อการตัดสินใจ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การใช้ภาษาชี้นำทำให้ผู้ใช้ตัดสินใจด้วยอารมณ์ แทนเหตุผลที่เป็นกลาง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 4,
    "หัวข้อ": "แนวคิด “Think, Don’t Just Sync!”",
    "คำถาม": "ข้อความนี้ต้องการสื่อสารหลักการใด",
    "ตัวเลือก A": "ให้ใช้ AI โดยไม่ตั้งคำถาม",
    "ตัวเลือก B": "ให้ใช้ AI เพื่อเลียนแบบมนุษย์",
    "ตัวเลือก C": "ให้ใช้ AI อย่างมีสติ คิดวิเคราะห์ ไม่เชื่อโดยง่าย",
    "ตัวเลือก D": "ให้ใช้ AI เฉพาะด้านเทคนิคเท่านั้น",
    "คำตอบที่ถูก": "C",
    "คำอธิบาย": "เน้นการใช้ AI อย่างมีวิจารณญาณ ใช้การคิดเชิงวิเคราะห์มากกว่าการเชื่อตามทันที",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 4,
    "หัวข้อ": "ตัวอย่างคำตอบเรื่องดาวพุธร้อนกว่าดาวศุกร์",
    "คำถาม": "ตัวอย่างนี้ต้องการสื่อถึงหลักการใดในการประเมินคำตอบจาก AI",
    "ตัวเลือก A": "ตรวจสอบความสอดคล้องกับความรู้พื้นฐานที่เราทราบอยู่แล้ว",
    "ตัวเลือก B": "เชื่อข้อมูลใหม่มากกว่าข้อมูลเก่า",
    "ตัวเลือก C": "ใช้ความรู้สึกตัดสินว่า AI ผิด",
    "ตัวเลือก D": "ตรวจสอบเฉพาะส่วนแรกของคำตอบ",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "ผู้ใช้ควรเปรียบเทียบข้อมูลจาก AI กับความรู้ทางวิทยาศาสตร์หรือข้อมูลที่ยืนยันได้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 4,
    "หัวข้อ": "การอ้างชื่อแหล่งข้อมูลหรือสถาบัน",
    "คำถาม": "ทำไมการที่ AI อ้างแหล่งข้อมูลไม่ได้หมายความว่าข้อมูลนั้นถูกต้องเสมอ",
    "ตัวเลือก A": "เพราะบางครั้ง AI อาจแต่งชื่อสถาบันหรือปีงานวิจัยขึ้นมาเอง",
    "ตัวเลือก B": "เพราะ AI ไม่เข้าใจภาษาอังกฤษ",
    "ตัวเลือก C": "เพราะสถาบันนั้นไม่มีอยู่จริง",
    "ตัวเลือก D": "เพราะข้อมูลทุกอย่างในอินเทอร์เน็ตผิดหมด",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "AI สามารถ “สร้าง” แหล่งข้อมูลปลอมได้ จึงต้องตรวจสอบซ้ำเสมอ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 4,
    "หัวข้อ": "การขาดแหล่งอ้างอิงเป็นสัญญาณเตือนสำคัญของข้อมูลที่ไม่น่าเชื่อถือ",
    "คำถาม": "หาก AI ให้คำตอบโดยไม่มีแหล่งอ้างอิง ผู้ใช้ควรทำอย่างไร",
    "ตัวเลือก A": "เชื่อทันทีเพราะ AI ฉลาด",
    "ตัวเลือก B": "ป้อนคำถามใหม่และขอให้ระบุแหล่งอ้างอิง",
    "ตัวเลือก C": "ปิดระบบและไม่ใช้ AI อีก",
    "ตัวเลือก D": "คัดลอกคำตอบไปโพสต์ต่อ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การขอแหล่งอ้างอิงหรือค้นต่อจากหลายระบบช่วยตรวจสอบความถูกต้องของข้อมูล",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 4,
    "หัวข้อ": "AI ไม่ได้ “คิด” แต่ “คาดเดา” คำถัดไปจากข้อมูลที่เคยเรียนรู้",
    "คำถาม": "เพราะเหตุใด AI บางครั้งจึงให้คำตอบผิดหรือแต่งเรื่องขึ้นมาเอง",
    "ตัวเลือก A": "เพราะ AI จงใจโกหก",
    "ตัวเลือก B": "เพราะ AI เดาคำตอบตามรูปแบบของข้อมูลที่เคยเห็น",
    "ตัวเลือก C": "เพราะระบบขัดข้อง",
    "ตัวเลือก D": "เพราะไม่มีมนุษย์ควบคุม",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI ไม่ได้เข้าใจความหมายจริง แต่คาดเดาคำถัดไปตามรูปแบบข้อมูล จึงอาจเกิด “Hallucination” ได้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 4,
    "หัวข้อ": "ตัวอย่างคำตอบ “นักกีฬาทุกคนออกกำลังกาย → ถ้าอยากสำเร็จต้องออกกำลังกาย”",
    "คำถาม": "ตัวอย่างนี้สะท้อนตรรกะผิดพลาดแบบใด",
    "ตัวเลือก A": "False Equivalence",
    "ตัวเลือก B": "Correlation is not causation",
    "ตัวเลือก C": "Circular Reasoning",
    "ตัวเลือก D": "Appeal to Emotion",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI สรุปผิดว่า “สิ่งที่มักเกิดร่วมกัน” เป็น “เหตุและผล” ซึ่งเป็นการให้เหตุผลที่ไม่สมเหตุสมผล",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 5,
    "หัวข้อ": "สรุปแนวคิด “Think, Don’t Just Sync!”",
    "คำถาม": "ข้อความนี้ในบริบทของบทนี้หมายถึงอะไร",
    "ตัวเลือก A": "ใช้ AI โดยไม่ต้องตรวจสอบ",
    "ตัวเลือก B": "หยุดคิดก่อนเชื่อหรือแชร์ข้อมูลใด ๆ ที่ได้จาก AI",
    "ตัวเลือก C": "ใช้ AI ให้เร็วที่สุดเพื่อไม่ตกเทรนด์",
    "ตัวเลือก D": "ให้ AI ตัดสินแทนมนุษย์ทั้งหมด",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "“Think, Don’t Just Sync!” เน้นให้ใช้วิจารณญาณ ตรวจสอบก่อนเชื่อหรือแชร์ข้อมูลในยุคของ AI",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 5,
    "หัวข้อ": "การใช้เทคโนโลยีตรวจสอบมนุษย์ เช่น การสแกนม่านตา",
    "คำถาม": "ข้อดีและข้อกังวลของการใช้เทคโนโลยีสแกนม่านตาคืออะไร",
    "ตัวเลือก A": "ปลอดภัยและไม่มีข้อจำกัด",
    "ตัวเลือก B": "ช่วยยืนยันความเป็นมนุษย์แต่มีความเสี่ยงด้านความเป็นส่วนตัว",
    "ตัวเลือก C": "ใช้ได้เฉพาะกับโทรศัพท์รุ่นใหม่",
    "ตัวเลือก D": "ตรวจจับ Deepfake ได้ 100%",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "แม้เทคโนโลยีช่วยยืนยันตัวตนได้ แต่ยังมีความกังวลด้านข้อมูลส่วนบุคคล",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 5,
    "หัวข้อ": "การตั้งคำถามส่วนตัวในครอบครัว",
    "คำถาม": "ทำไมการตั้ง “คำถามลับเฉพาะ” ในครอบครัวจึงช่วยป้องกันมิจฉาชีพได้",
    "ตัวเลือก A": "เพราะทำให้การสนทนาดูน่าสนุกขึ้น",
    "ตัวเลือก B": "เพราะคำถามเฉพาะตัวจะยืนยันตัวตนที่ Deepfake เลียนแบบไม่ได้",
    "ตัวเลือก C": "เพราะช่วยให้ AI เรียนรู้ข้อมูลส่วนตัว",
    "ตัวเลือก D": "เพราะช่วยลดความเครียดของผู้รับสาย",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Deepfake ไม่สามารถตอบคำถามส่วนตัวที่ไม่มีในข้อมูลออนไลน์ได้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 5,
    "หัวข้อ": "การป้องกันมิจฉาชีพ Deepfake โทรหลอก",
    "คำถาม": "หากได้รับสายจากคนที่อ้างว่าเป็นคนในครอบครัวแต่เสียงแปลกไป ควรทำอย่างไร",
    "ตัวเลือก A": "เชื่อทันทีเพราะชื่อขึ้นตรง",
    "ตัวเลือก B": "วางสายแล้วโทรกลับไปที่เบอร์จริงที่เราบันทึกไว้",
    "ตัวเลือก C": "ถามข้อมูลบัญชีเพื่อยืนยันตัวตน",
    "ตัวเลือก D": "แชร์เรื่องนี้ในโซเชียลมีเดีย",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การตรวจสอบโดยโทรกลับเบอร์จริงของคนในครอบครัวเป็นวิธีป้องกัน Deepfake โทรหลอก",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 5,
    "หัวข้อ": "เสียงใน Deepfake มักไม่สมบูรณ์แบบ",
    "คำถาม": "สัญญาณของเสียงปลอมใน Deepfake คือข้อใด",
    "ตัวเลือก A": "มีเสียงลมหายใจและเสียงพื้นหลังตามธรรมชาติ",
    "ตัวเลือก B": "มีจังหวะการพูดที่ไม่ปกติและเสียงราบเรียบเกินจริง",
    "ตัวเลือก C": "เสียงดังเกินไป",
    "ตัวเลือก D": "พูดเร็วและกระชับ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "เสียงจาก Deepfake มักฟังดูเป็นหุ่นยนต์ มีจังหวะเว้นวรรคไม่ธรรมชาติ และขาดอารมณ์จริง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 5,
    "หัวข้อ": "การสังเกตการกะพริบตาและแสงเงา",
    "คำถาม": "ข้อใดเป็นวิธีพื้นฐานในการตรวจจับวิดีโอ Deepfake",
    "ตัวเลือก A": "ตรวจสอบความเร็วในการพูดของผู้พูด",
    "ตัวเลือก B": "สังเกตการกะพริบตาและขอบใบหน้าที่เบลอผิดธรรมชาติ",
    "ตัวเลือก C": "เชื่อเฉพาะวิดีโอที่มาจากโซเชียลมีเดียดัง ๆ",
    "ตัวเลือก D": "ใช้ AI วิเคราะห์เท่านั้น",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Deepfake มักมีจุดผิดธรรมชาติ เช่น การกะพริบตาไม่สม่ำเสมอ หรือแสงบนใบหน้าไม่สมจริง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 5,
    "หัวข้อ": "Deepfake คือสื่อสังเคราะห์ที่ปลอมแปลงภาพ เสียง หรือวิดีโอ",
    "คำถาม": "Deepfake อันตรายอย่างไร",
    "ตัวเลือก A": "ทำให้ดูน่าสนุกและสร้างสรรค์",
    "ตัวเลือก B": "สามารถใช้หลอกลวงหรือบิดเบือนข้อมูลได้อย่างแนบเนียน",
    "ตัวเลือก C": "ใช้ได้เฉพาะในวงการภาพยนตร์",
    "ตัวเลือก D": "ไม่สามารถทำให้คนเชื่อได้จริง",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Deepfake เป็นภัยเพราะสามารถสร้างภาพหรือวิดีโอปลอมที่สมจริง ใช้ในการหลอกลวงได้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 5,
    "หัวข้อ": "AI อาจอ้างอิงบทความวิชาการที่ไม่มีอยู่จริง",
    "คำถาม": "หาก AI ให้ลิงก์งานวิจัยที่ดูน่าเชื่อถือแต่ไม่มีอยู่จริง ผู้ใช้ควรทำอย่างไร",
    "ตัวเลือก A": "แชร์ต่อเพราะดูจริง",
    "ตัวเลือก B": "ตรวจสอบซ้ำจากฐานข้อมูลวิชาการ เช่น Google Scholar",
    "ตัวเลือก C": "ปล่อยผ่านเพราะไม่สำคัญ",
    "ตัวเลือก D": "เชื่อทันทีถ้าอ้างชื่อมหาวิทยาลัยดัง",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การตรวจสอบซ้ำจากแหล่งที่เชื่อถือได้คือวิธีป้องกันการหลงเชื่อข้อมูลปลอม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 5,
    "หัวข้อ": "AI สามารถช่วยค้นหางานวิจัยได้อย่างรวดเร็ว แต่ก็อาจสร้างข้อมูลปลอมขึ้นมา",
    "คำถาม": "ปัญหา “Hallucination” ของ AI หมายถึงอะไร",
    "ตัวเลือก A": "การที่ AI ตอบช้ากว่าปกติ",
    "ตัวเลือก B": "การที่ AI สร้างข้อมูลหรือแหล่งอ้างอิงที่ไม่มีอยู่จริง",
    "ตัวเลือก C": "การที่ AI ปฏิเสธการตอบคำถาม",
    "ตัวเลือก D": "การที่ AI แปลภาษาผิด",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Hallucination คือการที่ AI “แต่งข้อมูล” หรือสร้างสิ่งที่ไม่มีอยู่จริงอย่างแนบเนียน",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 5,
    "หัวข้อ": "กรณีพนักงานบริษัทในฮ่องกงถูกหลอกโอนเงิน 896 ล้านบาท",
    "คำถาม": "หลักการทางจิตวิทยาใดที่มิจฉาชีพใช้ในเหตุการณ์นี้",
    "ตัวเลือก A": "Confirmation Bias",
    "ตัวเลือก B": "Social Proof",
    "ตัวเลือก C": "Authority Bias",
    "ตัวเลือก D": "Availability Heuristic",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "มิจฉาชีพใช้ Social Proof คือ “เมื่อทุกคนในกลุ่มเห็นด้วย สิ่งนั้นน่าจะถูกต้อง” เพื่อกดดันเหยื่อ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 6,
    "หัวข้อ": "การตอบโต้คอนเทนต์ไม่ชอบมากเกินไป",
    "คำถาม": "ถ้าเราคอมเมนต์โต้แย้งคอนเทนต์ที่ไม่ชอบบ่อย ๆ จะเกิดอะไรขึ้น",
    "ตัวเลือก A": "AI จะลดการแสดงคอนเทนต์นั้น",
    "ตัวเลือก B": "AI จะคิดว่าเราสนใจและแนะนำคอนเทนต์แบบเดียวกันเพิ่มขึ้น",
    "ตัวเลือก C": "ระบบจะลบคอนเทนต์นั้นออก",
    "ตัวเลือก D": "ไม่มีผลใด ๆ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การมีปฏิสัมพันธ์มาก (แม้จะเป็นเชิงลบ) ทำให้ AI เข้าใจผิดว่าเราสนใจเนื้อหานั้น",
    "หมายเหตุการรวม": null,
    "status": "checked"
  },
  {
    "Chapter": 6,
    "หัวข้อ": "สรุปแนวคิดหลักของบท",
    "คำถาม": "Personalization จะเป็นประโยชน์สูงสุดเมื่อใด",
    "ตัวเลือก A": "เมื่อเราเข้าใจกลไกและใช้เพื่อเพิ่มคุณภาพชีวิตและการเรียนรู้",
    "ตัวเลือก B": "เมื่อเราเปิดให้ระบบเลือกทุกอย่างแทนเรา",
    "ตัวเลือก C": "เมื่อเราใช้เวลามากที่สุดกับเนื้อหาที่เดิม",
    "ตัวเลือก D": "เมื่อเราไม่แสดงพฤติกรรมใด ๆ ในระบบ",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "การเข้าใจกลไกทำให้ผู้ใช้ใช้ AI อย่างมีอำนาจ ไม่ถูกระบบควบคุม",
    "หมายเหตุการรวม": null,
    "status": "checked"
  },
  {
    "Chapter": 6,
    "หัวข้อ": "การรักษาสมดุลในการใช้ระบบแนะนำ",
    "คำถาม": "วิธีใดช่วยให้ฟีดของเราหลากหลายมากขึ้น",
    "ตัวเลือก A": "กดโต้ตอบกับเนื้อหาแบบเดิมซ้ำ ๆ",
    "ตัวเลือก B": "เปิดใจรับเนื้อหาหลากหลายและเลือกโต้ตอบสิ่งใหม่ ๆ",
    "ตัวเลือก C": "ปิดระบบแนะนำทั้งหมด",
    "ตัวเลือก D": "ลบข้อมูลการใช้งานออกทุกวัน",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การโต้ตอบกับสิ่งใหม่ ๆ ทำให้ระบบเรียนรู้ความสนใจที่หลากหลายขึ้น",
    "หมายเหตุการรวม": null,
    "status": "checked"
  },
  {
    "Chapter": 6,
    "หัวข้อ": "ความเสี่ยงของการเจอแต่สิ่งซ้ำ ๆ (Echo Chamber)",
    "คำถาม": "ปัญหา Echo Chamber ส่งผลอย่างไร",
    "ตัวเลือก A": "ทำให้ผู้ใช้ได้รับข้อมูลที่หลากหลายมากขึ้น",
    "ตัวเลือก B": "ทำให้ผู้ใช้เห็นแต่เนื้อหาที่เหมือนเดิมและจำกัดมุมมอง",
    "ตัวเลือก C": "ทำให้ระบบแม่นยำขึ้นเสมอ",
    "ตัวเลือก D": "ไม่มีผลต่อพฤติกรรมผู้ใช้",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Echo Chamber ทำให้มุมมองของผู้ใช้แคบลงและเสี่ยงต่อการรับข้อมูลซ้ำแบบมีอคติ",
    "หมายเหตุการรวม": null,
    "status": "checked"
  },
  {
    "Chapter": 6,
    "หัวข้อ": "ความเสี่ยงของการใช้ AI โดยไม่เข้าใจกลไก",
    "คำถาม": "ถ้าเราไม่เข้าใจการทำงานของระบบแนะนำ จะเกิดผลอย่างไร",
    "ตัวเลือก A": "เราจะควบคุมเนื้อหาที่เห็นได้มากขึ้น",
    "ตัวเลือก B": "เราอาจกลายเป็นผู้ถูกควบคุมโดยอัลกอริทึม",
    "ตัวเลือก C": "ระบบจะหยุดแนะนำเนื้อหาทันที",
    "ตัวเลือก D": "ไม่มีผลใด ๆ ต่อผู้ใช้",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การไม่เข้าใจกลไกทำให้เราถูกอัลกอริทึมชี้นำโดยไม่รู้ตัว",
    "หมายเหตุการรวม": null,
    "status": "checked"
  },
  {
    "Chapter": 6,
    "หัวข้อ": "เหตุผลที่ระบบอาจแนะนำสิ่งที่เรา “ไม่ชอบ”",
    "คำถาม": "ข้อใดต่อไปนี้ ไม่ใช่ เหตุผลที่ระบบแนะนำสิ่งไม่ตรงใจ",
    "ตัวเลือก A": "ผู้ใช้เคยใช้เวลาเยอะกับคอนเทนต์นั้น",
    "ตัวเลือก B": "ระบบสุ่มเสนอสิ่งใหม่เพื่อทดลอง",
    "ตัวเลือก C": "ระบบใช้ข้อมูลของเพื่อนที่ชอบสิ่งนั้น",
    "ตัวเลือก D": "ระบบเข้าใจอารมณ์ของผู้ใช้ผิด",
    "คำตอบที่ถูก": "D",
    "คำอธิบาย": "AI ไม่ได้เข้าใจอารมณ์ของมนุษย์ แต่ใช้รูปแบบข้อมูลและเวลาเป็นหลักในการคาดเดา",
    "หมายเหตุการรวม": null,
    "status": "checked"
  },
  {
    "Chapter": 6,
    "หัวข้อ": "AI เข้าใจผู้ใช้โดย “เดา” จากข้อมูล ไม่ได้อ่านใจได้จริง",
    "คำถาม": "การที่ระบบแนะนำสามารถเดาได้ว่าเราชอบอะไร สะท้อนหลักการใด",
    "ตัวเลือก A": "การเรียนรู้จากตัวอย่าง (Learning from Data)",
    "ตัวเลือก B": "การเข้าใจอารมณ์ผู้ใช้",
    "ตัวเลือก C": "การสุ่มแบบไม่มีรูปแบบ",
    "ตัวเลือก D": "การเรียนรู้เชิงจิตวิทยา",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "ระบบใช้ข้อมูลจำนวนมากเพื่อเรียนรู้รูปแบบความสนใจของผู้ใช้",
    "หมายเหตุการรวม": null,
    "status": "checked"
  },
  {
    "Chapter": 6,
    "หัวข้อ": "ระบบเรียนรู้จากพฤติกรรม เช่น การกดไลก์ การดูวิดีโอ หรือการซื้อสินค้า",
    "คำถาม": "ข้อมูลใดต่อไปนี้มีผลต่อการแนะนำของ AI มากที่สุด",
    "ตัวเลือก A": "ข้อมูลที่ผู้ใช้พิมพ์เท่านั้น",
    "ตัวเลือก B": "พฤติกรรมการโต้ตอบของผู้ใช้ เช่น การกดไลก์และเวลาที่ใช้กับคอนเทนต์",
    "ตัวเลือก C": "ข้อมูลจากเพื่อนเท่านั้น",
    "ตัวเลือก D": "การตั้งค่าภาษาในเครื่อง",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "พฤติกรรมของผู้ใช้ (implicit feedback) เป็นตัวบ่งชี้หลักที่ระบบใช้เรียนรู้ความสนใจ",
    "หมายเหตุการรวม": null,
    "status": "checked"
  },
  {
    "Chapter": 6,
    "หัวข้อ": "การใช้ Recommendation System ในการศึกษา",
    "คำถาม": "การนำ AI มาปรับการเรียนรู้ให้เหมาะกับแต่ละบุคคลมีประโยชน์อย่างไร",
    "ตัวเลือก A": "ทุกคนได้เรียนเหมือนกันหมด",
    "ตัวเลือก B": "ผู้เรียนแต่ละคนได้รับเนื้อหาที่ตรงกับระดับและความสนใจ",
    "ตัวเลือก C": "ครูไม่ต้องสอนอีกต่อไป",
    "ตัวเลือก D": "ผู้เรียนต้องแข่งขันกันมากขึ้น",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Personalized learning ช่วยให้แต่ละคนเรียนในระดับและรูปแบบที่เหมาะสมกับตนเอง",
    "หมายเหตุการรวม": null,
    "status": "checked"
  },
  {
    "Chapter": 6,
    "หัวข้อ": "ระบบแนะนำ (Recommendation System) ช่วยเลือกสิ่งที่ “น่าจะใช่สำหรับเรา”",
    "คำถาม": "ระบบ Recommendation System ทำงานอย่างไร",
    "ตัวเลือก A": "คาดเดาจากสิ่งที่ผู้ใช้น่าจะสนใจโดยอิงจากพฤติกรรมการใช้งาน",
    "ตัวเลือก B": "สุ่มเนื้อหาทั้งหมดให้ผู้ใช้เลือกเอง",
    "ตัวเลือก C": "ให้ผู้เชี่ยวชาญเลือกเนื้อหาให้ผู้ใช้",
    "ตัวเลือก D": "แนะนำเฉพาะสิ่งที่ผู้ใช้ไม่เคยเห็นมาก่อน",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "ระบบใช้ข้อมูลการดู คลิก หรือซื้อของผู้ใช้มาคาดเดาสิ่งที่ผู้ใช้น่าจะชอบ",
    "หมายเหตุการรวม": null,
    "status": "checked"
  },
  {
    "Chapter": 7,
    "หัวข้อ": "บทสรุป",
    "คำถาม": "1ข้อใดสอดคล้องกับแนวคิด “AI for All” มากที่สุด",
    "ตัวเลือก A": "ให้ AI พัฒนาเฉพาะด้านเทคโนโลยีชั้นสูง",
    "ตัวเลือก B": "ให้ทุกคนสามารถเข้าถึงและใช้ AI ได้อย่างเท่าเทียม",
    "ตัวเลือก C": "ให้ผู้เชี่ยวชาญเท่านั้นใช้ AI",
    "ตัวเลือก D": "ให้ AI ทำงานแทนมนุษย์ทั้งหมด",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "“AI for All” หมายถึงการทำให้เทคโนโลยีตอบโจทย์คนทุกกลุ่มอย่างเท่าเทียมและทั่วถึง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "หัวใจของการพัฒนา AI ที่ดีที่สุด",
    "คำถาม": "1หลักคิด “Human-Centered AI” เน้นสิ่งใด",
    "ตัวเลือก A": "การพัฒนาเทคโนโลยีที่เน้นผลกำไรสูงสุด",
    "ตัวเลือก B": "การพัฒนาโดยมีมนุษย์และคุณภาพชีวิตเป็นศูนย์กลาง",
    "ตัวเลือก C": "การลดต้นทุนทางเทคนิค",
    "ตัวเลือก D": "การใช้ข้อมูลให้มากที่สุด",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Human-Centered AI คือการสร้างเทคโนโลยีที่ยกระดับคุณภาพชีวิตและลดความเหลื่อมล้ำ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "ความท้าทายของ AI เพื่อทุกคน",
    "คำถาม": "1ข้อใด ไม่ใช่ ความท้าทายในการออกแบบ AI ที่ครอบคลุมทุกกลุ่ม",
    "ตัวเลือก A": "Bias ของ AI",
    "ตัวเลือก B": "การปกป้องข้อมูลส่วนบุคคล",
    "ตัวเลือก C": "ค่าใช้จ่ายและความพร้อมของผู้ใช้",
    "ตัวเลือก D": "ความต้องการให้ระบบแนะนำซ้ำเดิม",
    "คำตอบที่ถูก": "D",
    "คำอธิบาย": "ปัญหา Echo Chamber เกี่ยวข้องกับการแนะนำเนื้อหา ไม่ใช่การเข้าถึงของผู้ใช้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "AI ในวงการศึกษา",
    "คำถาม": "1บทบาทของ AI ใน Blended Learning คืออะไร",
    "ตัวเลือก A": "เป็นผู้สอนแทนครูทั้งหมด",
    "ตัวเลือก B": "ช่วยปรับเนื้อหาและกิจกรรมให้เหมาะกับผู้เรียนแต่ละคน",
    "ตัวเลือก C": "จัดสอบแทนครู",
    "ตัวเลือก D": "ทำหน้าที่ควบคุมนักเรียน",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI ทำหน้าที่เป็นผู้ช่วยวิเคราะห์ความเข้าใจและแนะนำเนื้อหาที่เหมาะกับแต่ละคน",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "AI ลดอุปสรรคทางภาษา",
    "คำถาม": "แอปแปลภาษาที่ใช้เสียงพูดช่วยสร้างความเท่าเทียมได้อย่างไร",
    "ตัวเลือก A": "ช่วยให้เข้าใจเนื้อหาที่ซับซ้อนขึ้น",
    "ตัวเลือก B": "ทำให้ผู้ใช้ต่างชาติเข้าถึงบริการสาธารณะได้เท่าเทียม",
    "ตัวเลือก C": "ใช้เฉพาะในการท่องเที่ยว",
    "ตัวเลือก D": "ช่วยให้ผู้เรียนฝึกสำเนียง",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI ช่วยแปลภาษาแบบเรียลไทม์ ทำให้ผู้ใช้ต่างชาติหรือผู้ย้ายถิ่นเข้าถึงบริการได้เท่ากับคนท้องถิ่น",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "การช่วยนักเรียนที่มีปัญหาด้านการเรียนรู้ (LD, Dyslexia)",
    "คำถาม": "เทคโนโลยีใดเหมาะกับผู้เรียนที่มี Dyslexia",
    "ตัวเลือก A": "ระบบแปลภาษาอัตโนมัติ",
    "ตัวเลือก B": "ระบบ Text-to-Speech ที่อ่านเนื้อหาออกเสียง",
    "ตัวเลือก C": "ระบบตรวจสอบภาพ",
    "ตัวเลือก D": "ระบบพิมพ์ดีดเร็ว",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Text-to-Speech ช่วยให้นักเรียนที่อ่านหนังสือยากเข้าใจเนื้อหาได้ดีขึ้นโดยการฟัง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "AI ช่วยผู้สูงอายุ",
    "คำถาม": "ข้อใดต่อไปนี้เป็นตัวอย่างของการใช้ AI เพื่อดูแลผู้สูงอายุ",
    "ตัวเลือก A": "เกมออนไลน์เพื่อสุขภาพจิต",
    "ตัวเลือก B": "หุ่นยนต์เพื่อนพูดคุย เตือนยา และตรวจจับการล้ม",
    "ตัวเลือก C": "ระบบจำลองสภาพอากาศ",
    "ตัวเลือก D": "แอปแปลภาษาต่างประเทศ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI ช่วยผู้สูงอายุได้ทั้งด้านความปลอดภัยและอารมณ์ผ่านผู้ช่วยอัจฉริยะและหุ่นยนต์ดูแล",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "การช่วยเหลือผู้พิการทางการได้ยิน",
    "คำถาม": "เทคโนโลยีใดช่วยให้ผู้บกพร่องทางการได้ยินเข้าถึงข้อมูลได้มากขึ้น",
    "ตัวเลือก A": "โปรแกรมคำนวณคณิตศาสตร์",
    "ตัวเลือก B": "แอปแปลงเสียงพูดเป็นข้อความแบบเรียลไทม์",
    "ตัวเลือก C": "กล้องรักษาความปลอดภัย",
    "ตัวเลือก D": "แอปสั่งอาหารออนไลน์",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การแปลงเสียงเป็นข้อความช่วยให้ผู้บกพร่องทางการได้ยินเข้าใจบทสนทนาได้ทันที",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "ประโยชน์ข้อที่ 1: การช่วยเหลือผู้ที่มีความต้องการพิเศษ",
    "คำถาม": "ตัวอย่างใดแสดงถึงการใช้ AI เพื่อช่วยผู้พิการทางสายตา",
    "ตัวเลือก A": "ระบบตรวจจับใบหน้า",
    "ตัวเลือก B": "แอปอ่านข้อความบนหน้าจอและบรรยายสิ่งรอบตัว",
    "ตัวเลือก C": "ระบบจดจำเสียงของผู้ใช้",
    "ตัวเลือก D": "แอปแปลภาษาอัตโนมัติ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI ช่วยบรรยายสิ่งรอบตัวให้ผู้พิการทางสายตาผ่านเสียงได้แบบเรียลไทม์",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "การฝึกโมเดลด้วยข้อมูลที่หลากหลาย",
    "คำถาม": "ทำไมข้อมูลฝึก AI ต้องมีความหลากหลาย",
    "ตัวเลือก A": "เพื่อให้โมเดลซับซ้อนขึ้น",
    "ตัวเลือก B": "เพื่อป้องกันการเกิดอคติและตอบสนองผู้ใช้ทุกกลุ่มได้",
    "ตัวเลือก C": "เพื่อให้ระบบทำงานช้าลง",
    "ตัวเลือก D": "เพื่อสร้างภาพจำของผู้ใช้กลุ่มเดียว",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ความหลากหลายของข้อมูลช่วยลด Bias และเพิ่มความเท่าเทียมในการตัดสินใจของ AI",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "Human-Centered Design",
    "คำถาม": "Human-Centered Design เน้นหลักการใด",
    "ตัวเลือก A": "ให้ AI ตัดสินใจแทนมนุษย์",
    "ตัวเลือก B": "พัฒนาเทคโนโลยีที่ตอบโจทย์ความต้องการของมนุษย์อย่างแท้จริง",
    "ตัวเลือก C": "ลดต้นทุนของผู้ผลิตเท่านั้น",
    "ตัวเลือก D": "พัฒนาเพื่อกลุ่มเฉพาะที่ใช้ได้ดี",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การออกแบบโดยยึดมนุษย์เป็นศูนย์กลาง ทำให้เทคโนโลยีตอบสนองต่อผู้ใช้ทุกกลุ่มได้จริง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "องค์ประกอบของการออกแบบที่ครอบคลุม",
    "คำถาม": "แนวคิดใดที่เป็นสามเสาหลักของการออกแบบเพื่อทุกคน",
    "ตัวเลือก A": "Inclusivity, Accessibility, Usability",
    "ตัวเลือก B": "Simplicity, Speed, Design",
    "ตัวเลือก C": "Privacy, Creativity, Innovation",
    "ตัวเลือก D": "Accessibility, Security, Automation",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "การรวมทุกกลุ่ม (Inclusivity) การเข้าถึงได้ (Accessibility) และการใช้งานจริง (Usability) คือหัวใจของ Human-Centered Design",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "แนวคิด Inclusive Design",
    "คำถาม": "Inclusive Design หมายถึงอะไร",
    "ตัวเลือก A": "การออกแบบเฉพาะสำหรับผู้ใช้ที่มีความพิการ",
    "ตัวเลือก B": "การออกแบบเทคโนโลยีที่คำนึงถึงความหลากหลายของผู้ใช้ทุกกลุ่ม",
    "ตัวเลือก C": "การออกแบบระบบที่ใช้ AI ขั้นสูงเท่านั้น",
    "ตัวเลือก D": "การออกแบบเพื่อความสะดวกของผู้พัฒนา",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Inclusive Design คือการออกแบบเทคโนโลยีให้ทุกคนเข้าถึงได้โดยไม่ถูกจำกัดด้วยเพศ อายุ ภาษา หรือสภาพร่างกาย",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 7,
    "หัวข้อ": "การแปลเป็นภาษามือด้วยอวาตาร์",
    "คำถาม": "ข้อใดคือประโยชน์ของการใช้ AI แปลเสียงพูดเป็นภาษามือผ่านอวาตาร์",
    "ตัวเลือก A": "ทำให้คนทั่วไปเรียนภาษามือได้เร็วขึ้น",
    "ตัวเลือก B": "ลดช่องว่างการสื่อสารระหว่างคนหูหนวกกับคนทั่วไป",
    "ตัวเลือก C": "ช่วยให้หุ่นยนต์เข้าใจมนุษย์มากขึ้น",
    "ตัวเลือก D": "ใช้เฉพาะในวงการเกม",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI ภาษามือช่วยสร้างการสื่อสารที่เท่าเทียมระหว่างผู้บกพร่องทางการได้ยินกับสังคม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "ประโยชน์ของการที่ AI เข้าใจอารมณ์",
    "คำถาม": "ข้อใดเป็นประโยชน์โดยตรงของ Emotional AI",
    "ตัวเลือก A": "ใช้แทนนักจิตวิทยาได้โดยสมบูรณ์",
    "ตัวเลือก B": "ช่วยวิเคราะห์อารมณ์ของผู้ใช้และปรับการตอบสนองให้เหมาะสม",
    "ตัวเลือก C": "ทำให้ AI มีความรู้สึกจริง",
    "ตัวเลือก D": "ลดความต้องการครูในโรงเรียน",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI ที่เข้าใจอารมณ์ช่วยเพิ่มประสิทธิภาพการสื่อสารและการบริการ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "Human-Centered AI",
    "คำถาม": "1แนวคิด “Human-Centered AI” ในบทนี้หมายถึงอะไร",
    "ตัวเลือก A": "AI ที่เน้นการเลียนแบบมนุษย์ทุกด้าน",
    "ตัวเลือก B": "AI ที่เข้าใจและตอบสนองต่อมนุษย์เพื่อยกระดับคุณภาพชีวิต",
    "ตัวเลือก C": "AI ที่ตัดสินใจแทนมนุษย์ทั้งหมด",
    "ตัวเลือก D": "AI ที่ไม่มีการควบคุมจากมนุษย์",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Human-Centered AI คือการพัฒนา AI ที่เข้าใจมนุษย์และใช้เพื่อสนับสนุน ไม่แทนที่มนุษย์",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "สรุป",
    "คำถาม": "1จากบทเรียนนี้ เราสามารถสรุปได้ว่า...",
    "ตัวเลือก A": "AI มีอารมณ์จริง ๆ แบบมนุษย์",
    "ตัวเลือก B": "AI ไม่มีอารมณ์ แต่เข้าใจและตอบสนองต่ออารมณ์ของมนุษย์ได้",
    "ตัวเลือก C": "AI ไม่สามารถวิเคราะห์อารมณ์ได้เลย",
    "ตัวเลือก D": "AI สามารถรู้สึกโกรธหรือเศร้าได้เอง",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI ไม่มีอารมณ์ แต่เข้าใจและจำลองการแสดงออกทางอารมณ์เพื่อสื่อสารกับมนุษย์ได้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "AI กับสุขภาพจิต",
    "คำถาม": "1ข้อใดคือการใช้ Emotional AI ในการดูแลสุขภาพจิต",
    "ตัวเลือก A": "วิเคราะห์อารมณ์จากเสียงหรือข้อความเพื่อช่วยตรวจจับภาวะเครียดหรือซึมเศร้า",
    "ตัวเลือก B": "แนะนำผลิตภัณฑ์ใหม่ตามความรู้สึก",
    "ตัวเลือก C": "ตรวจสอบอุณหภูมิร่างกาย",
    "ตัวเลือก D": "ส่งข้อความอัตโนมัติเมื่อผู้ใช้หัวเราะ",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "AI สามารถช่วยประเมินภาวะทางอารมณ์จากพฤติกรรมและการสื่อสารของผู้ใช้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "AI กับการเรียนรู้เฉพาะบุคคล",
    "คำถาม": "Emotional AI ช่วยสนับสนุน Personalized Learning ได้อย่างไร",
    "ตัวเลือก A": "ปรับเนื้อหาและวิธีสอนตามอารมณ์ผู้เรียน",
    "ตัวเลือก B": "ตรวจสอบผลสอบแทนครู",
    "ตัวเลือก C": "สอนเฉพาะวิชาคณิตศาสตร์",
    "ตัวเลือก D": "ตัดสินคะแนนอัตโนมัติ",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "AI สามารถวิเคราะห์อารมณ์ผู้เรียนและปรับเนื้อหาหรือวิธีสอนให้เหมาะสม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "สรุปภาพรวมของความสามารถ AI",
    "คำถาม": "จากองค์ประกอบของอารมณ์ทั้ง 5 ข้อใดถูกต้อง",
    "ตัวเลือก A": "AI มีอารมณ์ครบทุกองค์ประกอบ",
    "ตัวเลือก B": "AI ไม่มีอารมณ์แต่สามารถจำลองบางองค์ประกอบได้",
    "ตัวเลือก C": "AI ไม่สามารถวิเคราะห์อารมณ์มนุษย์ได้เลย",
    "ตัวเลือก D": "AI มีอารมณ์เหมือนมนุษย์ในอนาคต",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI ไม่มีความรู้สึกจริง แต่สามารถจำลองการแสดงออกและการประเมินเหตุการณ์ได้บางส่วน",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "AI กับการบริการลูกค้า",
    "คำถาม": "1Emotional AI ช่วยยกระดับประสบการณ์ลูกค้าได้อย่างไร",
    "ตัวเลือก A": "ตอบกลับด้วยข้อความมาตรฐานทุกครั้ง",
    "ตัวเลือก B": "ปรับโทนการตอบให้เหมาะกับอารมณ์ของลูกค้า",
    "ตัวเลือก C": "เก็บข้อมูลลูกค้าโดยไม่แจ้ง",
    "ตัวเลือก D": "ตัดสินใจแทนลูกค้า",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การเข้าใจอารมณ์ลูกค้าช่วยให้ AI สื่อสารอย่างเห็นอกเห็นใจและเพิ่มความพึงพอใจ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "การแสดงออกของ AI",
    "คำถาม": "Motor Expression ของ AI ปรากฏในรูปแบบใด",
    "ตัวเลือก A": "การเปลี่ยนสีหน้าและท่าทางแบบร่างกายจริง",
    "ตัวเลือก B": "การแสดงออกผ่านข้อความ เสียง หรือภาพ",
    "ตัวเลือก C": "การเปลี่ยนระดับพลังงาน",
    "ตัวเลือก D": "การส่งสัญญาณไฟฟ้าในวงจร",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI สามารถ “จำลอง” การแสดงออกได้ เช่น เสียง น้ำเสียง หรือภาพ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "การเปรียบเทียบองค์ประกอบของอารมณ์ใน AI",
    "คำถาม": "องค์ประกอบใดที่ AI ยัง “ไม่มี” อย่างแท้จริง",
    "ตัวเลือก A": "Cognitive Appraisal",
    "ตัวเลือก B": "Motor Expression",
    "ตัวเลือก C": "Subjective Feeling",
    "ตัวเลือก D": "Action Tendency",
    "คำตอบที่ถูก": "C",
    "คำอธิบาย": "AI ยังไม่มีความรู้สึกภายในหรือจิตสำนึก (Subjective Feeling) แบบมนุษย์",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "การตอบสนองทางกาย",
    "คำถาม": "ตัวอย่างของ Physiological Response คือข้อใด",
    "ตัวเลือก A": "การพูดด้วยน้ำเสียงนุ่มนวล",
    "ตัวเลือก B": "การหัวใจเต้นเร็ว เหงื่อออก หรือกล้ามเนื้อตึง",
    "ตัวเลือก C": "การยิ้มให้ผู้อื่น",
    "ตัวเลือก D": "การคิดวิเคราะห์ปัญหา",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "เป็นการตอบสนองทางกายภาพที่เกิดขึ้นโดยอัตโนมัติเมื่อมีอารมณ์",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "การประเมินเหตุการณ์",
    "คำถาม": "Cognitive Appraisal ในบริบทของอารมณ์หมายถึงอะไร",
    "ตัวเลือก A": "การตอบสนองของร่างกาย",
    "ตัวเลือก B": "การประเมินเหตุการณ์ว่าเกี่ยวข้องกับตนเองหรือควบคุมได้ไหม",
    "ตัวเลือก C": "การแสดงออกทางสีหน้า",
    "ตัวเลือก D": "การหลั่งฮอร์โมน",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "เป็นกระบวนการที่สมองประเมินว่าสถานการณ์นั้นสำคัญต่อเราหรือไม่",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "องค์ประกอบของอารมณ์",
    "คำถาม": "ข้อใด ไม่ใช่ องค์ประกอบของอารมณ์ตามแนวคิด Component Process Model",
    "ตัวเลือก A": "Cognitive Appraisal",
    "ตัวเลือก B": "Physiological Response",
    "ตัวเลือก C": "Machine Learning",
    "ตัวเลือก D": "Subjective Feeling",
    "คำตอบที่ถูก": "C",
    "คำอธิบาย": "Machine Learning เป็นเทคโนโลยี ไม่ใช่องค์ประกอบของอารมณ์มนุษย์",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "ความเข้าใจพื้นฐานของอารมณ์",
    "คำถาม": "ตามนิยามของ Klaus Scherer อารมณ์คืออะไร",
    "ตัวเลือก A": "การตอบสนองทางกายอย่างเดียว",
    "ตัวเลือก B": "การตอบสนองแบบประสานกันของความคิด ร่างกาย และการแสดงออกต่อเหตุการณ์",
    "ตัวเลือก C": "ความรู้สึกชั่ววูบที่เกิดขึ้นโดยไม่มีเหตุผล",
    "ตัวเลือก D": "ปฏิกิริยาที่เกิดจากสิ่งเร้าภายนอกเท่านั้น",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Scherer ให้นิยามอารมณ์ว่าเป็นการตอบสนองหลายองค์ประกอบ ทั้งความคิด ร่างกาย และพฤติกรรม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 8,
    "หัวข้อ": "แนวโน้มการกระทำ (Action Tendency)",
    "คำถาม": "เหตุใด Action Tendency ของ AI จึงไม่เหมือนมนุษย์",
    "ตัวเลือก A": "เพราะ AI ไม่มีเป้าหมายภายในและแรงจูงใจส่วนตัว",
    "ตัวเลือก B": "เพราะ AI ยังไม่ถูกตั้งโปรแกรม",
    "ตัวเลือก C": "เพราะ AI ไม่มีข้อมูลเพียงพอ",
    "ตัวเลือก D": "เพราะ AI ไม่เข้าใจภาษา",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "AI ตอบสนองตามคำสั่ง ไม่ได้ขับเคลื่อนด้วยแรงจูงใจหรืออารมณ์ภายใน",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "สรุปแนวคิดหลัก",
    "คำถาม": "1จากบทนี้ ผู้เรียนควรมีทัศนคติอย่างไรต่อ AI",
    "ตัวเลือก A": "มองว่าเป็นภัยต่อการเรียนรู้",
    "ตัวเลือก B": "มองว่าเป็นคู่คิดที่ช่วยขยายศักยภาพการเรียนรู้ของเรา",
    "ตัวเลือก C": "ใช้เพราะจำเป็นเท่านั้น",
    "ตัวเลือก D": "หลีกเลี่ยงเพราะไม่แม่นยำ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "บทเรียนนี้สรุปว่า AI คือเครื่องมือเพิ่มพลัง ไม่ใช่สิ่งมาทดแทนมนุษย์",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การออกแบบการเรียนรู้แห่งอนาคต",
    "คำถาม": "1บทเรียนจาก “กะทิ” บอกเราว่า AI ที่ดีควรถูกออกแบบอย่างไร",
    "ตัวเลือก A": "ให้ข้อมูลเยอะที่สุด",
    "ตัวเลือก B": "มีตัวตนชัดเจน เป็นมิตร และสอดคล้องกับเป้าหมายการเรียนรู้",
    "ตัวเลือก C": "ใช้ภาษาทางเทคนิคมาก",
    "ตัวเลือก D": "ตอบแบบสั้นกระชับทุกครั้ง",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "บุคลิกและบริบทที่เป็นมิตรทำให้การเรียนรู้กับ AI มีประสิทธิภาพ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การเชื่อมโยงกับชีวิตจริง",
    "คำถาม": "1หากผู้เรียนต้องใช้ Generative AI ในชีวิตประจำวัน สิ่งที่ควรระลึกเสมอคืออะไร",
    "ตัวเลือก A": "ใช้เพื่อให้ได้คำตอบเร็วที่สุด",
    "ตัวเลือก B": "ใช้อย่างมีเป้าหมายและสะท้อนตนเองหลังใช้งาน",
    "ตัวเลือก C": "ใช้เฉพาะในงานวิชาการ",
    "ตัวเลือก D": "หลีกเลี่ยงการใช้ AI",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การใช้ AI อย่างมีสติและมีเป้าหมายช่วยให้เกิดการเรียนรู้จริง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การใช้ AI เพื่อสร้างนวัตกรรม",
    "คำถาม": "“Vibe Coding” สะท้อนแนวคิดใดของการเรียนรู้ร่วมกับ AI",
    "ตัวเลือก A": "เรียนรู้ผ่านการลองผิดลองถูกและสร้างต้นแบบร่วมกับ AI",
    "ตัวเลือก B": "การฝึกจำคำสั่ง AI",
    "ตัวเลือก C": "การใช้โค้ดสำเร็จรูป",
    "ตัวเลือก D": "การเขียนโปรแกรมระดับสูง",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "“Vibe Coding” คือการให้ AI ช่วยจำลองแนวคิด สร้างต้นแบบ และฝึกคิดเชิงสร้างสรรค์",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การประยุกต์ใช้ในงานวิจัย",
    "คำถาม": "ถ้าใช้ AI เป็น “เพื่อนคู่คิด” ในงานวิจัย ควรใช้ในลักษณะใด",
    "ตัวเลือก A": "ให้ AI สรุปผลแทน",
    "ตัวเลือก B": "ให้ AI ตั้งคำถามและช่วยสะท้อนแนวคิดกลับ",
    "ตัวเลือก C": "ให้ AI เขียนบทความทั้งหมด",
    "ตัวเลือก D": "ให้ AI เก็บข้อมูลภาคสนาม",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การใช้ AI ตั้งคำถามกลับช่วยให้ผู้วิจัยคิดอย่างลึกและมีมุมมองใหม่",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การเรียนรู้ตลอดชีวิต",
    "คำถาม": "จากมุมมองของ รศ.ดร.สุทธิดา “AI” ทำหน้าที่เหมือนอะไรในกระบวนการเรียนรู้",
    "ตัวเลือก A": "ผู้ตรวจสอบผลงาน",
    "ตัวเลือก B": "เพื่อนคู่คิดที่ช่วยสะท้อนและตั้งคำถาม",
    "ตัวเลือก C": "เครื่องมือประเมินคะแนน",
    "ตัวเลือก D": "ระบบช่วยจำเนื้อหา",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "AI ถูกมองว่าเป็นเพื่อนร่วมคิดที่ช่วยให้ผู้เรียนมองเห็นช่องว่างของความเข้าใจ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การมอง AI อย่างมีวิจารณญาณ",
    "คำถาม": "“AI จะไม่ทำแทนเรา แต่เติบโตไปพร้อมกับเรา” หมายความว่าอย่างไร",
    "ตัวเลือก A": "มนุษย์ควบคุม AI ได้เสมอ",
    "ตัวเลือก B": "AI เป็นเครื่องมือสนับสนุนการเรียนรู้ของมนุษย์",
    "ตัวเลือก C": "AI จะกลายเป็นสิ่งมีชีวิต",
    "ตัวเลือก D": "AI ต้องเรียนรู้แบบเดียวกับคน",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "สะท้อนแนวคิด Human-Centered AI ที่เน้นการพัฒนาเพื่อร่วมเติบโตกับมนุษย์",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การประเมินผลหลังใช้ Chatbot",
    "คำถาม": "การที่คะแนน Net Promoter Score เพิ่มจาก -59 เป็น +34 สะท้อนอะไร",
    "ตัวเลือก A": "ระบบให้คะแนนผิดพลาด",
    "ตัวเลือก B": "ผู้เรียนพอใจและเห็นว่าทักษะตนดีขึ้น",
    "ตัวเลือก C": "จำนวนผู้เรียนลดลง",
    "ตัวเลือก D": "นักศึกษากลัว AI น้อยลง",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ค่า NPS ที่เพิ่มขึ้นหมายถึงประสบการณ์ผู้ใช้และทักษะดีขึ้นจริง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การเรียนรู้แบบมีผู้ช่วยอัจฉริยะ",
    "คำถาม": "การมี Chatbot อย่าง “กะทิ” ในห้องเรียนขนาดใหญ่ช่วยลดปัญหาใดได้ดีที่สุด",
    "ตัวเลือก A": "ขาดผู้ช่วยสอนดูแลรายคน",
    "ตัวเลือก B": "ขาดระบบอัตโนมัติ",
    "ตัวเลือก C": "ขาดอุปกรณ์คอมพิวเตอร์",
    "ตัวเลือก D": "ขาดคะแนนสอบ",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "Chatbot ทำหน้าที่เสมือน Facilitator ส่วนตัว สำหรับผู้เรียนจำนวนมาก",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "บทบาทของ Chatbot ในการเรียนรู้",
    "คำถาม": "ถ้า “กะทิ” เป็นผู้ช่วยสอน (TA) ที่ดี นักศึกษาควรใช้ประโยชน์อย่างไร",
    "ตัวเลือก A": "รอให้กะทิให้คำตอบที่ถูกต้อง",
    "ตัวเลือก B": "ใช้กะทิเป็นพื้นที่ฝึกตั้งคำถามและรับฟีดแบค",
    "ตัวเลือก C": "ใช้เพื่อค้นหาข้อสอบเก่า",
    "ตัวเลือก D": "ใช้แทนการอ่านหนังสือ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Chatbot ถูกออกแบบให้ช่วยพัฒนากระบวนการคิด ไม่ใช่ให้คำตอบแทน",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การเรียนรู้จาก Chatbot “กะทิ”",
    "คำถาม": "สิ่งสำคัญที่สุดที่ “กะทิ” ช่วยให้นักศึกษาเรียนรู้ได้คืออะไร",
    "ตัวเลือก A": "ได้คำตอบที่เร็วขึ้น",
    "ตัวเลือก B": "ได้ฝึกคิดและปรับปรุง Prompt ด้วยตนเอง",
    "ตัวเลือก C": "ได้เกรดสูงขึ้น",
    "ตัวเลือก D": "ได้เรียนรู้ข้อมูลใหม่ ๆ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "“กะทิ” ไม่สอนโดยให้คำตอบ แต่ฝึกให้ผู้เรียนคิดและพัฒนา Prompt ด้วยคำถามนำ",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การสื่อสารกับ AI",
    "คำถาม": "การฝึกสื่อสารกับ AI ผ่านการเขียน Prompt คล้ายกับทักษะ Soft Skill ใดมากที่สุด",
    "ตัวเลือก A": "การใช้โปรแกรมคอมพิวเตอร์",
    "ตัวเลือก B": "การพูดในที่สาธารณะ",
    "ตัวเลือก C": "การตั้งคำถามและสื่อสารกับคนอย่างมีเหตุผล",
    "ตัวเลือก D": "การจำคำสั่ง",
    "คำตอบที่ถูก": "C",
    "คำอธิบาย": "การสื่อสารกับ AI ต้องอาศัยการคิด วิเคราะห์ และตั้งคำถามอย่างมีจุดหมาย เหมือนการสนทนากับคน",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การเข้าใจปัญหาเริ่มต้น",
    "คำถาม": "เมื่อผู้เรียนรู้สึกว่าคำตอบจาก Generative AI “ไม่ตรงกับสิ่งที่ต้องการ” ควรเริ่มแก้จากจุดใดก่อน",
    "ตัวเลือก A": "ฝึกเขียน Prompt ให้ชัดเจนและมีบริบท",
    "ตัวเลือก B": "เปลี่ยนไปใช้โมเดล AI ตัวอื่น",
    "ตัวเลือก C": "ใช้หลาย Prompt พร้อมกัน",
    "ตัวเลือก D": "หยุดใช้ AI ทันที",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "ปัญหามักเกิดจากการสื่อสารไม่ชัด การฝึกตั้งคำถามหรือเขียน Prompt คือก้าวแรกของการแก้ปัญหา",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 9,
    "หัวข้อ": "การตีความจากกรณีศึกษา",
    "คำถาม": "จากกรณี “กะทิ” เราเรียนรู้อะไรได้เกี่ยวกับการใช้ AI เพื่อพัฒนาทักษะมนุษย์",
    "ตัวเลือก A": "AI ใช้แทนมนุษย์ได้ในทุกงาน",
    "ตัวเลือก B": "AI ช่วยพัฒนา Soft Skills ได้ หากออกแบบให้เรียนรู้เชิงปฏิสัมพันธ์",
    "ตัวเลือก C": "AI ควรใช้เฉพาะในด้านเทคนิค",
    "ตัวเลือก D": "AI ทำให้คนพึ่งพาเทคโนโลยีเกินไป",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ตัวอย่าง “กะทิ” แสดงให้เห็นว่า AI สามารถเสริมทักษะการคิดและการสื่อสารได้จริง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "มุมมองเชิงปรัชญา",
    "คำถาม": "ข้อคิดจากไฮเดกเกอร์เกี่ยวกับเทคโนโลยีเตือนเราว่าอะไร",
    "ตัวเลือก A": "เทคโนโลยีทำลายสิ่งแวดล้อม",
    "ตัวเลือก B": "เทคโนโลยีอาจเปลี่ยนแก่นแท้ของความเป็นมนุษย์ ทำให้เรามองทุกสิ่งเป็นเพียงเครื่องมือ",
    "ตัวเลือก C": "เทคโนโลยีควรถูกควบคุมโดยกฎหมายเท่านั้น",
    "ตัวเลือก D": "เทคโนโลยีไม่มีผลต่อความเป็นมนุษย์",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ไฮเดกเกอร์เตือนว่าการพึ่งพาเทคโนโลยีมากเกินไปอาจทำให้เราสูญเสียความเป็นมนุษย์",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "การใช้ AI อย่างชาญฉลาด",
    "คำถาม": "ผู้ใช้ควรทำสิ่งใดเพื่อใช้ AI อย่างชาญฉลาดและมีความรับผิดชอบ",
    "ตัวเลือก A": "เก็บข้อมูลการใช้งาน เช่น Prompt และเวอร์ชันของ AI ที่ใช้",
    "ตัวเลือก B": "ใช้โดยไม่สนใจผลลัพธ์",
    "ตัวเลือก C": "ให้ AI ทำงานทั้งหมดแทน",
    "ตัวเลือก D": "ใช้ AI โดยไม่เปิดเผยแหล่งที่มา",
    "คำตอบที่ถูก": "A",
    "คำอธิบาย": "การเก็บข้อมูลการใช้งานช่วยให้ตรวจสอบความโปร่งใสและรับผิดชอบต่อผลลัพธ์ได้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "สิทธิในทรัพย์สินทางปัญญา",
    "คำถาม": "เหตุใดผลงานที่สร้างโดย AI ล้วนๆ จึงไม่ได้รับลิขสิทธิ์",
    "ตัวเลือก A": "เพราะ AI ยังไม่เป็นที่ยอมรับในวงการศิลปะ",
    "ตัวเลือก B": "เพราะกฎหมายให้สิทธิ์เฉพาะมนุษย์ที่ใช้ความพยายามสร้างสรรค์งาน",
    "ตัวเลือก C": "เพราะ AI ไม่จ่ายภาษี",
    "ตัวเลือก D": "เพราะไม่สามารถพิสูจน์ผู้สร้างได้",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ลิขสิทธิ์มอบให้เฉพาะมนุษย์ที่มี “เจตนาและความพยายามสร้างสรรค์”",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "จริยธรรมและการตีพิมพ์",
    "คำถาม": "การใช้ AI ในการเขียนบทความวิชาการอย่างมีจริยธรรม ควรทำอย่างไร",
    "ตัวเลือก A": "ห้ามใช้ AI ทุกกรณี",
    "ตัวเลือก B": "ใช้ได้แต่ต้องระบุให้ชัดว่าช่วยในส่วนใด",
    "ตัวเลือก C": "ใช้ได้โดยไม่ต้องประกาศ",
    "ตัวเลือก D": "ให้ AI เขียนแทนทั้งหมด",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ผู้เขียนสามารถใช้ AI ช่วยในบางขั้นตอน แต่ต้องเปิดเผยวิธีการใช้อย่างโปร่งใส",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "หลักการสำคัญของกฎหมาย AI",
    "คำถาม": "ข้อใด “ไม่ใช่” ประเด็นหลักของกฎหมาย AI ที่กำลังพัฒนา",
    "ตัวเลือก A": "การคุ้มครองข้อมูลส่วนบุคคล",
    "ตัวเลือก B": "การป้องกันอคติและการบิดเบือนคำตอบ",
    "ตัวเลือก C": "การส่งเสริมการใช้ AI อย่างมีความรับผิดชอบ",
    "ตัวเลือก D": "การแบนการใช้ AI ในทุกกรณี",
    "คำตอบที่ถูก": "D",
    "คำอธิบาย": "ไม่มีประเทศใดออกกฎหมายห้ามใช้ AI แต่ส่งเสริมให้ใช้อย่างมีจริยธรรม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "กฎหมายในไทย",
    "คำถาม": "หน่วยงานใดของไทยกำลังพัฒนากรอบกฎหมาย AI",
    "ตัวเลือก A": "สำนักงานสถิติแห่งชาติ",
    "ตัวเลือก B": "สำนักงานพัฒนาธุรกรรมทางอิเล็กทรอนิกส์ (ETDA)",
    "ตัวเลือก C": "สำนักงานนวัตกรรมแห่งชาติ (NIA)",
    "ตัวเลือก D": "กระทรวงศึกษาธิการ",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "ETDA เป็นหน่วยงานหลักในการกำหนดกรอบกฎหมาย AI และทำประชาพิจารณ์แล้ว",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "อาชีพในอนาคต",
    "คำถาม": "เหตุใด AI ยังไม่สามารถแทนที่ครูได้ทั้งหมด",
    "ตัวเลือก A": "เพราะ AI ยังไม่ฉลาดพอ",
    "ตัวเลือก B": "เพราะครูมีบทบาทเกินกว่าการถ่ายทอดความรู้ เช่น การให้แรงบันดาลใจและความเข้าใจมนุษย์",
    "ตัวเลือก C": "เพราะกฎหมายห้าม",
    "ตัวเลือก D": "เพราะนักเรียนไม่ชอบใช้เทคโนโลยี",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "บทบาทของครูมีมิติทางอารมณ์ จริยธรรม และมนุษยสัมพันธ์ที่ AI ยังทำแทนไม่ได้",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "การกำกับดูแล AI",
    "คำถาม": "กฎหมายใดของสหภาพยุโรป (EU) เป็นต้นแบบการกำกับดูแล AI ที่ครอบคลุมที่สุด",
    "ตัวเลือก A": "Digital Service Act",
    "ตัวเลือก B": "EU AI Act",
    "ตัวเลือก C": "GDPR 2.0",
    "ตัวเลือก D": "European Data Law",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "EU AI Act เป็นกฎหมายต้นแบบที่กำหนดกรอบการพัฒนาและใช้ AI อย่างครอบคลุม",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "Agentic AI",
    "คำถาม": "Agentic AI แตกต่างจาก Chatbot ทั่วไปอย่างไร",
    "ตัวเลือก A": "ต้องมีคนสั่งงานตลอดเวลา",
    "ตัวเลือก B": "ทำงานอัตโนมัติเป็นกระบวนการครบวงจรโดยไม่ต้องสั่งทีละขั้น",
    "ตัวเลือก C": "ใช้เฉพาะงานแปลภาษา",
    "ตัวเลือก D": "ไม่มีความสามารถเชื่อมต่อระบบอื่น",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "Agentic AI สามารถทำงานเป็นลำดับต่อเนื่อง เช่น วิเคราะห์–สรุป–รายงาน ได้เอง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "ผลกระทบต่อทักษะมนุษย์",
    "คำถาม": "ความกังวลเรื่อง “Critical Thinking ถดถอย” เกิดจากอะไร",
    "ตัวเลือก A": "คนใช้ AI เพื่อแก้ปัญหาที่ยากเกินไป",
    "ตัวเลือก B": "การพึ่งพา AI สร้างเนื้อหาแทนการคิดวิเคราะห์เอง",
    "ตัวเลือก C": "การเขียน Prompt ผิด",
    "ตัวเลือก D": "การใช้ข้อมูลเก่าฝึก AI",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "เมื่อ AI ทำให้เราคิดน้อยลง ความสามารถในการวิเคราะห์เชิงลึกของมนุษย์อาจลดลง",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "แนวโน้มของ AI",
    "คำถาม": "ปัจจัยใดเป็นสาเหตุให้เกิดความกังวลเกี่ยวกับ Generative AI มากขึ้นในปัจจุบัน",
    "ตัวเลือก A": "การที่ AI ยังไม่สามารถคิดเองได้",
    "ตัวเลือก B": "การที่ AI เริ่มทำงานแทนมนุษย์ในกระบวนการซับซ้อนมากขึ้น",
    "ตัวเลือก C": "การที่ AI ใช้งานยากเกินไป",
    "ตัวเลือก D": "การที่ AI มีราคาสูง",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การพัฒนา Agentic AI ทำให้ AI เริ่มทำงานอัตโนมัติแทนมนุษย์ได้หลายขั้นตอน",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "การตั้งคำถามที่ถูกต้อง",
    "คำถาม": "ผู้ใช้ AI ที่ “ชาญฉลาด” ควรถามคำถามใดมากที่สุดก่อนเริ่มใช้งาน",
    "ตัวเลือก A": "AI จะทำงานได้เร็วแค่ไหน",
    "ตัวเลือก B": "เราควรให้ AI ทำอะไร และไม่ควรทำอะไร เพื่ออะไร",
    "ตัวเลือก C": "โมเดลไหนแม่นที่สุด",
    "ตัวเลือก D": "ใช้ AI แล้วประหยัดเวลาเท่าไร",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "การใช้ AI อย่างมีสติเริ่มจากการเข้าใจเป้าหมายและขอบเขตการใช้งาน",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "กฎหมายลิขสิทธิ์ในสหรัฐฯ",
    "คำถาม": "กฎหมาย Generative AI Copyright Disclosure Act มีเป้าหมายหลักคืออะไร",
    "ตัวเลือก A": "จำกัดการเข้าถึง AI",
    "ตัวเลือก B": "บังคับให้บริษัทเปิดเผยข้อมูลลิขสิทธิ์ที่ใช้ฝึก AI",
    "ตัวเลือก C": "ห้ามสร้างภาพด้วย AI",
    "ตัวเลือก D": "ยกเลิกการคุ้มครองผลงานมนุษย์",
    "คำตอบที่ถูก": "B",
    "คำอธิบาย": "เพื่อความโปร่งใส บริษัทต้องเปิดเผยว่ามีผลงานใดถูกใช้ในการเทรน AI",
    "หมายเหตุการรวม": null
  },
  {
    "Chapter": 10,
    "หัวข้อ": "เป้าหมายสูงสุดของการใช้ AI",
    "คำถาม": "จากบทเรียนนี้ จุดหมายสูงสุดของการใช้ AI คืออะไร",
    "ตัวเลือก A": "ให้ AI แทนแรงงานมนุษย์",
    "ตัวเลือก B": "เพิ่มผลิตภาพอย่างเดียว",
    "ตัวเลือก C": "ใช้ AI เพื่อทำให้มนุษย์ฉลาดขึ้นและเข้าใจโลกดีขึ้น",
    "ตัวเลือก D": "ใช้เพื่อสร้างความบันเทิง",
    "คำตอบที่ถูก": "C",
    "คำอธิบาย": "เป้าหมายคือการใช้ AI เพื่อเสริมศักยภาพของมนุษย์ ไม่ใช่ลดคุณค่าของมนุษย์",
    "หมายเหตุการรวม": null
  }
]